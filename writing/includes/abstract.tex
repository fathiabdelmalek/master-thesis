\begin{abstract}
	
	Sign language recognition (SLR) has been a challenging task due to the complexity of hand gestures and the variability among sign languages. This thesis presents Takalem gloves, a wearable device designed for SLR using deep learning techniques. The proposed architecture consists of two ESP32 microcontrollers, flex sensors, IMUs, and a speaker. The dataset was collected using the gloves and preprocessed using Python. The deep learning model is based on convolutional and recurrent neural networks and was trained and evaluated on the American Sign Language dataset. The results showed an accuracy of 97.5\% on a test set of 1,200 signs. The proposed approach has the potential to enhance the communication between the hearing-impaired and the hearing communities, and can be further developed for other sign languages.
\end{abstract}
\providecommand{\keywords}[1]
{
	\small	
	\textbf{\textit{Keywords---}} #1
}
\keywords{sign language recognition, artificial intelligence, machine learning, deep learning}