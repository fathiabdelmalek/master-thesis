\section{Sign language recognition}
\paragraph{}
\ac{slr} is the process of interpreting and translating the gestures, movements, and facial expressions of \ac{sl} into written or spoken language. It involves capturing, processing, and analyzing data from various sensors and devices such as gloves and cameras.
\paragraph{}
The task of \ac{slr} is a challenging one due to the complexity and variability of sign languages. Sign languages are rich and expressive, and there are many different sign languages used around the world, each with their own unique vocabulary, grammar, and syntax. Moreover, sign languages are not universal, meaning that a sign used in one language may have a completely different meaning in another language.
\paragraph{}
Despite these challenges, significant progress has been made in the field of \ac{slr} in recent years, thanks to advances in sensor technology, computer vision, \ac{ml} and \ac{dl}. Researchers have proposed a wide range of approaches to tackle the problem of \ac{slr}, including rule-based systems, template matching, \ac{hmm}, \ac{ann}, and \ac{dl} methods.
\paragraph{}
In recent years, \ac{dl}-based methods, particularly \ac{cnn} and \ac{rnn}, have shown promising results in \ac{slr}, achieving state-of-the-art performance on several benchmark datasets. These methods can learn meaningful representations of the data directly from raw input, which makes them well-suited to complex and dynamic data like \ac{sl}.