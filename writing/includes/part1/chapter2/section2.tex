\section{Datasets for Training and Evaluation}
\paragraph{}
Datasets are essential for training and evaluating \ac{slr} systems. These datasets are used to train \ac{slr} systems to recognize signs and to evaluate the accuracy of \ac{slr} systems.
\paragraph{}
There are a number of different datasets available. But the majority of them fall under one of the following three types.:
\begin{itemize}
	\item \textbf{Image-based datasets:} consist of static images capturing sign language gestures or symbols. These datasets are often derived from larger video datasets or captured explicitly for image-based recognition tasks.
	\item \textbf{Video-based datasets:} contain continuous sequences of sign language gestures or sentences. These datasets provide a more comprehensive representation of sign language and allow for temporal analysis.
	\item \textbf{Sensor-based datasets:} leverage various sensing modalities, such as gloves with sensors, depth cameras, or inertial measurement units (IMUs). These datasets capture the movements and positions of the signer's hands and body, enabling fine-grained analysis of sign language.
\end{itemize}
\paragraph{}
Here is a table with the most popular used datasets:
\begin{table}[h]
	\centering
	\caption{Standard datasets for \ac{sl} "\cite{5perc}}
	\begin{tabular}{|c|c|}
		\hline
		Dataset & Sign language\\
		\hline
		ASL-MNIST & ASL \\
		\hline
		Lifeprint Fingurespell Library & ASL \\
		\hline
		American Sign Language Linguistic Research Project with transcription using SignStream & ASL \\
		\hline
		ASL Lexicon Video Dataset & ASL \\
		\hline
		eNTERFACE & ASL \\
		\hline
		RWTH-BOSTON-104 Database & ASL \\
		\hline
		CAS-PEAL & CSL \\
		\hline
		PETS 2002 & PSL \\
		\hline
		BosphorusSign22k & TSM \\
		\hline
		K-RSL & K-RSL \\
		\hline
	\end{tabular}
\end{table}